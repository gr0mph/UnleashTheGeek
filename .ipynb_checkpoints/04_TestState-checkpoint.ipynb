{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_HOME     = 0\n",
    "AGENT_ANYWHERE = 1\n",
    "AGENT_ORE      = 2\n",
    "AGENT_RADAR    = 3\n",
    "AGENT_BURY     = 4\n",
    "#AGENT_TRAP     = 4\n",
    "\n",
    "\n",
    "ACTION_WAIT           = 0\n",
    "ACTION_DIG_ORE        = 1\n",
    "ACTION_DIG_SURELY_ORE = 2\n",
    "ACTION_DIG_BIG_RADAR  = 3\n",
    "ACTION_DIG_RADAR      = 4\n",
    "ACTION_REQUEST_RADAR  = 5\n",
    "ACTION_MOVE_HOME      = 6\n",
    "#ACTION_NONE           = 7\n",
    "\n",
    "class Agent:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.state = AGENT_HOME\n",
    "        self.action = ACTION_WAIT\n",
    "\n",
    "class AgentState:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.agent = []\n",
    "        self.size  = 0\n",
    "        self.start = 0\n",
    "        self.index = 0 \n",
    "        \n",
    "        \n",
    "    def append(self, Agent):\n",
    "        self.agent.append(Agent)\n",
    "        self.size = self.size + 1\n",
    "        \n",
    "    def pop(self):\n",
    "        self.agent.pop()\n",
    "        self.size = self.size - 1\n",
    "        self.start = self.start + 1\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.agent[index]\n",
    "        \n",
    "class Action:\n",
    "    \n",
    "    def available_functions(self):\n",
    "        if self.agent_state[-1].state == AGENT_HOME :\n",
    "            t_tuple = [-1] * 7\n",
    "            i = 0\n",
    "            for func_in_list in self.is_function_home :\n",
    "                if func_in_list is not None:\n",
    "                    t_tuple[i] = -1 if func_in_list() == None else 1\n",
    "                i = i + 1\n",
    "            t_tuple = tuple(t_tuple)\n",
    "            \n",
    "        elif self.agent_state[-1].state == AGENT_RADAR :\n",
    "            t_tuple = [-1] * 7\n",
    "            i = 0\n",
    "            for func_in_list in self.is_function_radar :\n",
    "                if func_in_list is not None:\n",
    "                    t_tuple[i] = -1 if func_in_list() == None else 1\n",
    "                i = i + 1\n",
    "            t_tuple = tuple(t_tuple)\n",
    "\n",
    "        elif self.agent_state[-1].state == AGENT_ANYWHERE :\n",
    "            t_tuple = [-1] * 7\n",
    "            t_tuple[self.agent_state[-1].action] = 1\n",
    "            t_tuple = tuple(t_tuple)\n",
    "            \n",
    "        elif self.agent_state[-1].state == AGENT_ORE :\n",
    "            t_tuple = [-1] * 7\n",
    "            t_tuple[ACTION_MOVE_HOME] = 1\n",
    "            t_tuple = tuple(t_tuple)\n",
    "            \n",
    "        elif self.agent_state[-1].state == AGENT_BURY :\n",
    "            t_tuple = [-1] * 7\n",
    "            t_tuple[ACTION_WAIT] = 1\n",
    "            t_tuple = tuple(t_tuple)\n",
    "        \n",
    "        return t_tuple\n",
    "    \n",
    "    def call_functions(self, index):\n",
    "        if self.agent_state[-1].state == AGENT_HOME :\n",
    "            self.list_function_home[index]()\n",
    "        \n",
    "        elif self.agent_state[-1].state == AGENT_ANYWHERE :\n",
    "            self.list_function_anywhere[index]()\n",
    "        \n",
    "        elif self.agent_state[-1].state == AGENT_ORE :\n",
    "            self.list_function_ore[index]()\n",
    "            \n",
    "        elif self.agent_state[-1].state == AGENT_RADAR :\n",
    "            self.list_function_radar[index]()\n",
    "        \n",
    "        elif self.agent_state[-1].state == AGENT_BURY :\n",
    "            self.list_function_bury[index]()\n",
    "        \n",
    "    \n",
    "    def isOre(self):\n",
    "        result = random.randint(1,20)\n",
    "        current_agent = self.agent_state[-1]\n",
    "        if result >= self.hazardous :\n",
    "            if current_agent.state == AGENT_HOME :\n",
    "                self.distance_ore = random.randint(0, 20)\n",
    "            if current_agent.state == AGENT_ANYWHERE :\n",
    "                self.distance_ore = random.randint(0, 16)\n",
    "            return (self.distance_ore)\n",
    "        return None\n",
    "\n",
    "    def isSurelyOre(self):\n",
    "        result = random.randint(1,20)\n",
    "        current_agent = self.agent_state[-1]\n",
    "        if result >= self.hazardous :\n",
    "            if current_agent.state == AGENT_HOME :\n",
    "                self.distance_surely_ore = random.randint(0, 20)\n",
    "            if current_agent.state == AGENT_ANYWHERE :\n",
    "                self.distance_surely_ore = random.randint(0, 16)\n",
    "            return (self.distance_surely_ore)\n",
    "        return None\n",
    "\n",
    "    def isBigRadar(self):\n",
    "        if self.distance_big_radar <= 0 :\n",
    "            self.distance_big_radar = random.randint(-1,11)\n",
    "\n",
    "        if self.distance_big_radar == -1:\n",
    "            return None\n",
    "        return (self.distance_big_radar)\n",
    "\n",
    "    def isRadar(self):\n",
    "        if self.distance_radar <= 0 :\n",
    "            self.distance_radar = random.randint(-1,7)\n",
    "\n",
    "        if self.distance_radar == -1:\n",
    "            return None\n",
    "        return (self.distance_radar)\n",
    "\n",
    "    def isRequestRadar(self):\n",
    "        return 1\n",
    "\n",
    "    def waiting(self):\n",
    "        current_agent = self.agent_state[-1]\n",
    "        self.agent_state.append(current_agent)\n",
    "        self.agent_state.pop()\n",
    "        return None\n",
    "    \n",
    "    def digOre(self):\n",
    "        current_agent = self.agent_state[-1]\n",
    "        if self.distance_ore <= 1 :\n",
    "            result = random.randint(-2,20)\n",
    "            if result <= -1 :\n",
    "                current_agent.state = AGENT_BURY\n",
    "            else :\n",
    "                current_agent.state = AGENT_ORE\n",
    "            current_agent.action = ACTION_NONE\n",
    "        \n",
    "        else :\n",
    "            self.distance_ore = self.distance_ore - 4\n",
    "            self.distance_ore = self.distance_ore if self.distance_ore > 0 else 0\n",
    "            self.action = ACTION_DIG_ORE if self.distance_ore > 0 else ACTION_WAIT\n",
    "        \n",
    "        self.agent_state.append(current_agent)\n",
    "        self.agent_state.pop()\n",
    "        return None\n",
    "\n",
    "    def digSurelyOre(self):\n",
    "        current_agent = self.agent_state[-1]\n",
    "        if self.distance_surely_ore <= 1 :\n",
    "            result = random.randint(-4,20)\n",
    "            if result <= -1 :\n",
    "                current_agent.state = AGENT_BURY\n",
    "            else :\n",
    "                current_agent.state = AGENT_ORE\n",
    "            current_agent.action = ACTION_NONE\n",
    "        \n",
    "        else :\n",
    "            self.distance_surely_ore = self.distance_surely_ore - 4\n",
    "            self.distance_surely_ore = self.distance_surely_ore if self.distance_surely_ore > 0 else 0\n",
    "            self.action = ACTION_DIG_SURELY_ORE if self.distance_surely_ore > 0 else ACTION_WAIT\n",
    "        \n",
    "        self.agent_state.append(current_agent)\n",
    "        self.agent_state.pop()\n",
    "        return None\n",
    "        \n",
    "    def digBigRadar(self):\n",
    "        current_agent = self.agent_state[-1]\n",
    "        if self.distance_big_radar <= 1 :\n",
    "            result = random.randint(-2,20)\n",
    "            if result <= -1 :\n",
    "                current_agent.state = AGENT_BURY\n",
    "            elif result == 0 :\n",
    "                current_agent.state = AGENT_ORE\n",
    "                self.hazardous = self.hazardous - 2\n",
    "                self.hazardous = self.hazardous if self.hazardous > self.min_hazardous else self.min_hazardous\n",
    "            else:\n",
    "                current.agent_state = AGENT_ANYWHERE\n",
    "                self.hazardous = self.hazardous - 2\n",
    "                self.hazardous = self.hazardous if self.hazardous > self.min_hazardous else self.min_hazardous\n",
    "            current_agent.action = ACTION_NONE\n",
    "        \n",
    "        else :\n",
    "            self.distance_big_radar = self.distance_big_radar - 4\n",
    "            self.distance_big_radar = self.distance_big_radar if self.distance_big_radar > 0 else 0\n",
    "            self.action = ACTION_DIG_BIG_RADAR if self.distance_big_radar > 0 else ACTION_NONE\n",
    "        \n",
    "        self.agent_state.append(current_agent)\n",
    "        self.agent_state.pop()\n",
    "        return None\n",
    "        \n",
    "    def digRadar(self):\n",
    "        current_agent = self.agent_state[-1]\n",
    "        if self.distance_big_radar <= 1 :\n",
    "            result = random.randint(-2,20)\n",
    "            if result <= -1 :\n",
    "                current_agent.state = AGENT_BURY\n",
    "            elif result == 0 :\n",
    "                current_agent.state = AGENT_ORE\n",
    "                self.hazardous = self.hazardous - 1\n",
    "                self.hazardous = self.hazardous if self.hazardous > self.min_hazardous else self.min_hazardous\n",
    "            else:\n",
    "                current.agent_state = AGENT_ANYWHERE\n",
    "                self.hazardous = self.hazardous - 1\n",
    "                self.hazardous = self.hazardous if self.hazardous > self.min_hazardous else self.min_hazardous\n",
    "            current_agent.action = ACTION_NONE\n",
    "        \n",
    "        else :\n",
    "            self.distance_big_radar = self.distance_big_radar - 4\n",
    "            self.distance_big_radar = self.distance_big_radar if self.distance_big_radar > 0 else 0\n",
    "            self.action = ACTION_DIG_RADAR if self.distance_big_radar > 0 else ACTION_NONE\n",
    "        \n",
    "        self.agent_state.append(current_agent)\n",
    "        self.agent_state.pop()\n",
    "        return None\n",
    "        \n",
    "    def requestRadar(self):\n",
    "        current_agent = self.agent_state[-1]\n",
    "        #if current_agent.state == AGENT_ORE :\n",
    "        #    self.score = self.score + 1\n",
    "        #    current_agent.state = AGENT_RADAR\n",
    "        #else :\n",
    "        #    current_agent.state = AGENT_RADAR\n",
    "        current_agent.state = AGENT_RADAR\n",
    "        self.agent_state.append(current_agent)\n",
    "        self.agent_state.pop()\n",
    "        return None\n",
    "        \n",
    "    def goHome(self):\n",
    "        current_agent = self.agent_state[-1]\n",
    "        self.score = self.score + 1\n",
    "        current_agent.state = AGENT_HOME\n",
    "        self.agent_state.append(current_agent)\n",
    "        self.agent_state.pop()\n",
    "        return None\n",
    "        \n",
    "    def __init__(self):\n",
    "        self.is_okay = True\n",
    "        self.hazardous = 20\n",
    "        self.min_hazardous = 5\n",
    "        \n",
    "        self.distance_ore = -1\n",
    "        self.distance_surely_ore = -1\n",
    "        self.distance_radar = -1\n",
    "        self.distance_big_radar = -1\n",
    "        \n",
    "        self.list_function_home     = (None   , self.digOre, self.digSurelyOre, None       , None    , self.requestRadar, None  )\n",
    "        self.list_function_anywhere = (None   , self.digOre, self.digSurelyOre, None       , None    , None        , None  )\n",
    "        self.list_function_ore      = (None   , None  , None        , None       , None    , None        , self.goHome)\n",
    "        self.list_function_radar    = (None   , self.digOre, self.digSurelyOre, self.digBigRadar, self.digRadar, None        , None  )\n",
    "        self.list_function_bury     = (self.waiting, None  , None        , None       , None    , None        , None  )\n",
    "        \n",
    "        self.is_function_home       = (None, self.isOre, self.isSurelyOre, None      , None   , self.isRequestRadar, None )\n",
    "        self.is_function_radar      = (None, self.isOre, self.isSurelyOre, self.isBigRadar, self.isRadar, None          , None )\n",
    "        \n",
    "        self.agent_state = AgentState()\n",
    "        self.score = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q Learning simple program\n",
    "\n",
    "From this site\n",
    "\n",
    "https://www.linkedin.com/pulse/simple-q-learning-algorithm-python-surya-kari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R \n",
      "[[ -1.   0.   0.  -1.  -1.   0.  -1.]\n",
      " [ -1.   0.   0.  -1.  -1.  -1.  -1.]\n",
      " [ -1.  -1.  -1.  -1.  -1.  -1. 100.]\n",
      " [ -1.   0.   0.   0.   0.  -1.  -1.]\n",
      " [  0.  -1.  -1.  -1.  -1.  -1.  -1.]]\n",
      "Q \n",
      "[[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "environment = [(0,0,1),(1,0,2),(2,0,5),(3,1,1),(4,1,2),(5,2,6),(6,3,1),(7,3,2),(8,3,3),(9,3,4),(10,4,0)]\n",
    "\n",
    "states = 5\n",
    "actions = 7\n",
    "goal = 5\n",
    "\n",
    "## R reward matrix\n",
    "R = np.matrix(np.ones(shape=[states,actions]))\n",
    "R = R * -1\n",
    "\n",
    "for (i,x,y) in environment:\n",
    "    R[x,y] = 100 if i == goal else 0\n",
    "\n",
    "## Q quality matrix : Our brain\n",
    "Q = np.matrix(np.zeros(shape=[states,actions]))\n",
    "\n",
    "print('R \\n{}'.format(R))\n",
    "print('Q \\n{}'.format(Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Please refer to the image above for better clarity \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"1) Please refer to the image above for better clarity \\n\")\n",
    "\n",
    "action = Action()\n",
    "agent = Agent()\n",
    "\n",
    "agent_state = action.agent_state\n",
    "agent_state.append(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1, -1, -1, -1, -1, 1, -1)\n",
      "[[-1 -1 -1 -1 -1  1 -1]]\n",
      "[5]\n"
     ]
    }
   ],
   "source": [
    "actions = action.available_functions()\n",
    "result = np.array([[i for i in actions]])\n",
    "av_actions = np.where(result >= 0)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "def choose_random_action(actions):\n",
    "    action = random.choice(actions)\n",
    "    return action\n",
    "\n",
    "action = choose_random_action(av_actions)\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.8\n",
    "def Q_update(state,action,gamma):\n",
    "    # First the max Q part\n",
    "    Max_Q = np.max(Q[action,])\n",
    "    Q[state,action] = R[state,action] + gamma * Max_Q\n",
    "    return Q\n",
    "\n",
    "Q = Q_update(currentstate,action,gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1) Please refer to the image above for better clarity \\n\")\n",
    "\n",
    "action = Action()\n",
    "agent = Agent()\n",
    "\n",
    "agent_state = action.agent_state\n",
    "agent_state.append(agent)\n",
    "\n",
    "state = agent_state[-1].state\n",
    "\n",
    "def available_actions(state):\n",
    "    rewards_row_state = R[state,]\n",
    "    \n",
    "    if state == AGENT_HOME :\n",
    "        for i in \n",
    "        \n",
    "    elif state == AGENT_RADAR :\n",
    "    \n",
    "    av_actions = np.where(rewards_row_state >= 0)[1] # In our case, any value ge 0 is a possible action we can take from our current state\n",
    "    return av_actions\n",
    "    \n",
    "actions = available_actions(currentstate)\n",
    "print(\"2) As we can see, the available actions from state {} is {} \\n\".format(current_state,actions))\n",
    "\n",
    "# Lets say, we choose one action from the available actions, so we choose randomly\n",
    "\n",
    "def choose_random_action(actions):\n",
    "    action = random.choice(actions)\n",
    "    return action\n",
    "\n",
    "action = choose_random_action(actions)\n",
    "print(\"3) The action we have chosen to take is to go to {}, from state {} \\n\".format(action,current_state))\n",
    "\n",
    "# we now have information about our current state, current action we are taking, \n",
    "# and possible next states and actions we can take\n",
    "\n",
    "gamma = 0.8\n",
    "\n",
    "print(\"4) Here we have pause a little and introduce a hyper parameter called Gamma\")\n",
    "print(\"   Gamma is a paramter that is used to control if the model needs to focus on immediate reward or future rewards \\n\")\n",
    "\n",
    "# Now we develop our Q update function\n",
    "\n",
    "print(\"5) The Equation for our Q learner is as follows\")\n",
    "print(\"   Q[state,action] = R[state,action] + gamma * Max(Q[next state,all_actions])\")\n",
    "\n",
    "def Q_update(state,action,gamma):\n",
    "    # First the max Q part\n",
    "    Max_Q = np.max(Q[action,])\n",
    "    Q[state,action] = R[state,action] + gamma * Max_Q\n",
    "    return Q\n",
    "\n",
    "Q = Q_update(currentstate,action,gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
